{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e",
   "metadata": {
    "id": "a1c98c44-0505-43b2-957c-86aa4d0e621e"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qk4Uw_iSr3Mc",
   "metadata": {
    "id": "Qk4Uw_iSr3Mc"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 7:** Retrieval-Augmented Generation with Vector Stores</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "In the previous notebook, we learned about embedding models and exercised some of their capabilities. We discussed their intended use cases of longer-form document comparison and found ways to use it as a backbone for more custom semantic comparisons. This notebook will progress these ideas toward the retrieval model's intended use case and explore how to build chatbot systems that rely on *vector stores* to automatically save and retrieve information.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "- Understand how semantic-similarity-backed systems can facilitate easy-to-use retrieval formulations.\n",
    "\n",
    "- Learn how to incorporate retrieval modules into your chat model systems for a retrieval-augmented generation (RAG) pipeline, which can be applied to tasks like document retrieval and conversation memory buffers.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Questions To Think About:**\n",
    "\n",
    "- This notebook does not attempt to incorporate hierarchical reasoning or non-naive RAG (such as planning agents). Consider what modifications would be necessary to make these components work in an LCEL chain.\n",
    "\n",
    "- Consider when it would be best to move your vector store solution into a scalable service and when a GPU will become necessary for optimization.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5XmeiiOWtuxC",
   "metadata": {
    "id": "5XmeiiOWtuxC"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "## ^^ Comment out if you want to see the pip install process\n",
    "\n",
    "## Necessary for Colab, not necessary for course environment\n",
    "# %pip install -q langchain langchain-nvidia-ai-endpoints gradio rich\n",
    "# %pip install -q arxiv pymupdf faiss-cpu\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fe234-2bdb-4107-8483-efda9aa5e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf",
   "metadata": {
    "id": "a3ced9b0-30ed-4ccc-936f-ca03d6e172bf"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## Part 1: Summary of RAG Workflows\n",
    "\n",
    "This notebook will explore several paradigms and derive reference code to help you approach some of the most common retrieval-augmented workflows. Specifically, the following sections will be covered (with the differences highlighted):\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***Vector Store Workflow for Conversational Exchanges:***\n",
    "- Generate semantic embedding for each new conversation.\n",
    "- Add the message body to a vector store for retrieval.\n",
    "- Query the vector store for relevant messages to fill in the LLM context.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ***Modified Workflow for an Arbitrary Document:***\n",
    "- **Divide the document into chunks and process them into useful messages.**\n",
    "- Generate semantic embedding for each **new document chunk**.\n",
    "- Add the **chunk bodies** to a vector store for retrieval.\n",
    "- Query the vector store for relevant **chunks** to fill in the LLM context.\n",
    "    - ***Optional:* Modify/synthesize results for better LLM results.**\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Extended Workflow for a Directory of Arbitrary Documents:**\n",
    "- Divide **each document** into chunks and process them into useful messages.\n",
    "- Generate semantic embedding for each new document chunk.\n",
    "- Add the chunk bodies to **a scalable vector database for fast retrieval**.\n",
    "    - ***Optional*: Exploit hierarchical or metadata structures for larger systems.**\n",
    "- Query the **vector database** for relevant chunks to fill in the LLM context.\n",
    "    - *Optional:* Modify/synthesize results for better LLM results.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some of the most important terminology surrounding RAG is covered in detail on the [**LlamaIndex Concepts page**](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html), which itself is a great starting point for progressing towards the LlamaIndex loading and retrieving strategy. We highly recommend using it as a reference as you continue with this notebook and advise you to try out LlamaIndex after the course to consider the pros and cons firsthand!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437",
   "metadata": {
    "id": "baa1911b-a6a2-47c5-bc66-1b61e6516437"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1cFbKbVvLLnFPs3yWCKIuzXkhBWh6nLQY\" width=1200px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/data_connection_langchain.jpeg\" width=1200px/>\n",
    ">\n",
    "> From [**Retrieval | LangChain**ü¶úÔ∏èüîó](https://python.langchain.com/v0.1/docs/modules/data_connection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XaZ20XoeSTD-",
   "metadata": {
    "id": "XaZ20XoeSTD-"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 2:** RAG for Conversation History\n",
    "\n",
    "In our previous explorations, we delved into the capabilities of document embedding models and used them to embed, store, and compare semantic vector representations of text. Though we could motivate how to efficiently extend this into vector store land manually, the true beauty of working with a standard API is its strong incorporation with other frameworks that can already do the heavy lifting for us!\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LRx0XUf_Sdxw",
   "metadata": {
    "id": "LRx0XUf_Sdxw"
   },
   "source": [
    "### **Step 1**: Getting A Conversation\n",
    "\n",
    "Consider a conversation crafted using Llama-13B between a chat agent and a blue bear named Beras. This dialogue, dense with details and potential diversions, provides a rich dataset for our study:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IUfCuMkoShWI",
   "metadata": {
    "id": "IUfCuMkoShWI"
   },
   "outputs": [],
   "source": [
    "conversation = [  ## This conversation was generated partially by an AI system, and modified to exhibit desirable properties\n",
    "    \"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the rocky mountains?\",\n",
    "    \"[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America\",\n",
    "    \"[Beras] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard many great things about them.\",\n",
    "    \"[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for you!\"\n",
    "    \"[Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.\",\n",
    "    \"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research online or watching documentaries about them.\"\n",
    "    \"[Beras] I live in the arctic, so I'm not used to the warm climate there. I was just curious, ya know!\",\n",
    "    \"[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains and their significance!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tDL2tAo2Skh2",
   "metadata": {
    "id": "tDL2tAo2Skh2"
   },
   "source": [
    "Using the manual embedding strategy from the previous notebook is still very viable, but we can also rest easy and let a **vector store** do all that work for us!\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5hIp943mSqGZ",
   "metadata": {
    "id": "5hIp943mSqGZ"
   },
   "source": [
    "### **Step 2:** Constructing Our Vector Store Retriever\n",
    "\n",
    "To streamline similarity queries on our conversation, we can employ a vector store to help keep track of passages for us! **Vector Stores**, or vector storage systems, abstract away most of the low-level details of the embedding/comparison strategies and provide a simple interface to load and compare vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pnaOBgexS-kp",
   "metadata": {
    "id": "pnaOBgexS-kp"
   },
   "source": [
    "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1ZjwYbSZzsXK6ZP8O1-cY3BeRffV4oqzb\" width=1000px/> -->\n",
    "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/vector_stores.jpeg\" width=1200px/>\n",
    ">\n",
    "> From [**Vector Stores | LangChain**ü¶úÔ∏èüîó](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DwZUh6kgS5Ki",
   "metadata": {
    "id": "DwZUh6kgS5Ki"
   },
   "source": [
    "<br>\n",
    "\n",
    "In addition to simplifying the process from an API perspective, vector stores also implement connectors, integrations, and optimizations under the hood. In our case, we will start with the [**FAISS vector store**](https://python.langchain.com/docs/integrations/vectorstores/faiss), which integrates a LangChain-compatable Embedding model with the [**FAISS (Facebook AI Similarity Search)**](https://github.com/facebookresearch/faiss) library to make the process fast and scalable on our local machine!\n",
    "\n",
    "**Specifically:**\n",
    "\n",
    "1. We can feed our conversation into [**a FAISS vector store**](https://python.langchain.com/docs/integrations/vectorstores/faiss) via the `from_texts` constructor. This will take our conversational data and the embedding model to create a searchable index over our discussion.\n",
    "2. This vector store can then be \"interpreted\" as a retriever, supporting the LangChain runnable API and returning documents retrieved via an input query.\n",
    "\n",
    "The following shows how you can construct a FAISS vector store and reinterpret it as a retriever using the LangChain `vectorstore` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1kE2-ejoTKKU",
   "metadata": {
    "id": "1kE2-ejoTKKU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 414 ms, total: 634 ms\n",
      "Wall time: 8.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ^^ This cell will be timed to see how long the conversation embedding takes\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "## Streamlined from_texts FAISS vectorstore construction from text list\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muN66v5PW5dW",
   "metadata": {
    "id": "muN66v5PW5dW"
   },
   "source": [
    "The retriever can now be used like any other LangChain runnable to query the vector store for some relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kNZJTnlEWVYh",
   "metadata": {
    "id": "kNZJTnlEWVYh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'b3378a38-b6ad-4cbe-bdc8-deae87eadccd'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'f102d070-bb0e-4993-89be-ac31c4cdf064'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'859adb9d-17a7-4aef-b3a6-f3fda3051c75'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you![Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'94a16deb-6604-47c7-9cb4-533b40296150'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'b3378a38-b6ad-4cbe-bdc8-deae87eadccd'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'f102d070-bb0e-4993-89be-ac31c4cdf064'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'859adb9d-17a7-4aef-b3a6-f3fda3051c75'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I hope you get to visit them someday, Beras! It would be a great adventure for \u001b[0m\n",
       "\u001b[32myou!\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Thank you for the suggestion! Ill definitely keep it in mind for the future.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'94a16deb-6604-47c7-9cb4-533b40296150'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SE1eDZTEWScC",
   "metadata": {
    "id": "SE1eDZTEWScC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'682fcf43-6a27-48f5-91ae-1931d0c1f272'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across North America'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'94a16deb-6604-47c7-9cb4-533b40296150'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">online or watching documentaries about them.[Beras] I live in the arctic, so I'm not used to the warm climate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there. I was just curious, ya know!\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'b3378a38-b6ad-4cbe-bdc8-deae87eadccd'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rocky mountains?\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'f102d070-bb0e-4993-89be-ac31c4cdf064'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">page_content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and their significance!'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    )</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'682fcf43-6a27-48f5-91ae-1931d0c1f272'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m The Rocky Mountains are a beautiful and majestic range of mountains that stretch \u001b[0m\n",
       "\u001b[32macross North America'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'94a16deb-6604-47c7-9cb4-533b40296150'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m In the meantime, you can learn more about the Rocky Mountains by doing some research \u001b[0m\n",
       "\u001b[32monline or watching documentaries about them.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mBeras\u001b[0m\u001b[32m]\u001b[0m\u001b[32m I live in the arctic, so I'm not used to the warm climate \u001b[0m\n",
       "\u001b[32mthere. I was just curious, ya know!\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'b3378a38-b6ad-4cbe-bdc8-deae87eadccd'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m]\u001b[0m\u001b[32m  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the \u001b[0m\n",
       "\u001b[32mrocky mountains?\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'f102d070-bb0e-4993-89be-ac31c4cdf064'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mmetadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mpage_content\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mAgent\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Absolutely! Lets continue the conversation and explore more about the Rocky Mountains\u001b[0m\n",
       "\u001b[32mand their significance!'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(retriever.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mtNCEXLYTVf4",
   "metadata": {
    "id": "mtNCEXLYTVf4"
   },
   "source": [
    "As we can see, our retriever found a handful of semantically relevant documents from our query. You may notice that not all of the documents are useful or clear on their own. For example, a retrieval of *\"Beras\"* for *\"your name\"* may be problematic for the chatbot if provided out of context. Anticipating the potential problems and creating synergies between your LLM components can increase the likelihood of good RAG behavior, so keep an eye out for such pitfalls and opportunities.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZEDEzpqmTYMv",
   "metadata": {
    "id": "ZEDEzpqmTYMv"
   },
   "source": [
    "### **Step 3:** Incorporating Conversation Retrieval Into Our Chain\n",
    "\n",
    "Now that we have our loaded retriever component as a chain, we can incorporate it into our existing chat system as before. Specifically, we can start with an ***always-on RAG formulation*** where:\n",
    "- **A retriever is always retrieving context by default**.\n",
    "- **A generator is acting on the retrieved context**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64abe478-9bcb-4802-a26e-dc5a1756e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Utility Runnables/Methods\n",
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        if preface: print(preface, end=\"\")\n",
    "        pprint(x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Optional; Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uue5UY3_TcvF",
   "metadata": {
    "id": "uue5UY3_TcvF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">It seems that Beras lives in the Arctic. The cooler climate there is quite different from the warm climate found in</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the Rocky Mountains, which Beras mentioned was of interest.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mIt seems that Beras lives in the Arctic. The cooler climate there is quite different from the warm climate found in\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe Rocky Mountains, which Beras mentioned was of interest.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {question}\"\n",
    "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | instruct_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"Where does Beras live?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FSIqTMuuTjIh",
   "metadata": {
    "id": "FSIqTMuuTjIh"
   },
   "source": [
    "Take a second to try out some more invocations and see how the new setup performs. Regardless of your model choice, the following questions should serve as interesting starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4jDJwrYpTmpd",
   "metadata": {
    "id": "4jDJwrYpTmpd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Hello there! The Rocky Mountains are a stunning range of mountains that span across North America. You can enjoy </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">their majestic beauty from here. I hope that helps! Let me know if you'd like to learn more about them.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mHello there! The Rocky Mountains are a stunning range of mountains that span across North America. You can enjoy \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtheir majestic beauty from here. I hope that helps! Let me know if you'd like to learn more about them.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "-artagLfTpBy",
   "metadata": {
    "id": "-artagLfTpBy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Hello there! The Rocky Mountains are a stunning range of mountains that stretch across North America. To answer </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">your question about their location, they run from northern British Columbia in Canada all the way down to New </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Mexico in the United States. As for their proximity to California, they don't directly border the state. The </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">closest parts of the Rocky Mountains to California would be in Nevada or Idaho, which are still quite a distance </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">away. I hope that helps! Let's continue exploring more about the Rocky Mountains if you have any other questions.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mHello there! The Rocky Mountains are a stunning range of mountains that stretch across North America. To answer \u001b[0m\n",
       "\u001b[1;38;2;118;185;0myour question about their location, they run from northern British Columbia in Canada all the way down to New \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mMexico in the United States. As for their proximity to California, they don't directly border the state. The \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mclosest parts of the Rocky Mountains to California would be in Nevada or Idaho, which are still quite a distance \u001b[0m\n",
       "\u001b[1;38;2;118;185;0maway. I hope that helps! Let's continue exploring more about the Rocky Mountains if you have any other questions.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains? Are they close to California?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GDgjdfdpTrV5",
   "metadata": {
    "id": "GDgjdfdpTrV5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">While I can't provide specifics on Beras's location, I can tell you that the Rocky Mountains span from western </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Canada all the way down to the southwestern United States. Without knowing Beras's exact location in the Arctic, I </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">can't determine the precise distance. However, given that Beras lives in the Arctic, they would be quite far from </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the Rocky Mountains.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWhile I can't provide specifics on Beras's location, I can tell you that the Rocky Mountains span from western \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mCanada all the way down to the southwestern United States. Without knowing Beras's exact location in the Arctic, I \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcan't determine the precise distance. However, given that Beras lives in the Arctic, they would be quite far from \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe Rocky Mountains.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"How far away is Beras from the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8wp9-8CbT0L9",
   "metadata": {
    "id": "8wp9-8CbT0L9"
   },
   "source": [
    "<br>\n",
    "\n",
    "You might notice some decent performance with this always-on retrieval node in the loop since the actual context being fed into the LLM remains relatively small. It's important to experiment with factors like embedding sizes, context limits, and model options to see what kinds of behavior you can expect and which efforts are worth taking to improve performance.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OnpOybOhUCTf",
   "metadata": {
    "id": "OnpOybOhUCTf"
   },
   "source": [
    "### **Step 4:** Automatic Conversation Storage\n",
    "\n",
    "Now that we see how our vector store memory unit should function, we can perform one last integration to allow our conversation to add new entries to our conversation: a runnable that calls the `add_texts` method for us to update the store state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "FsK6-AtRVdcZ",
   "metadata": {
    "id": "FsK6-AtRVdcZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">While I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying some ice cream, the context </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">only mentions the scenic beauty and significance of the Rockies, not any food options. However, we can certainly </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">agree that ice cream is a delicious treat, and perhaps imagining enjoying it amidst the breathtaking views of the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Rockies would make it even more enjoyable!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWhile I'm sure the Rocky Mountains would provide a magnificent backdrop for enjoying some ice cream, the context \u001b[0m\n",
       "\u001b[1;38;2;118;185;0monly mentions the scenic beauty and significance of the Rockies, not any food options. However, we can certainly \u001b[0m\n",
       "\u001b[1;38;2;118;185;0magree that ice cream is a delicious treat, and perhaps imagining enjoying it amidst the breathtaking views of the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mRockies would make it even more enjoyable!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">While I can't guess your favorite food with absolute certainty, based on our conversation, I can tell that you seem</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">to have a liking for ice cream! I'm sure enjoying ice cream amidst the magnificent Rocky Mountains would be a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">wonderful experience. Is ice cream one of your favorite foods?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWhile I can't guess your favorite food with absolute certainty, based on our conversation, I can tell that you seem\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mto have a liking for ice cream! I'm sure enjoying ice cream amidst the magnificent Rocky Mountains would be a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwonderful experience. Is ice cream one of your favorite foods?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Well, that's quite a delightful surprise! Honey is such a versatile and beneficial food, with a rich, sweet taste </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">that's hard to resist. In our conversation, you had mentioned enjoying ice cream, and I had associated that with </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">your favorite food. But it turns out, your favorite is the all-natural, golden sweetness of honey! I'm glad we got </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">that cleared up, and now I know a bit more about your preferences. Thank you for sharing that with me!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWell, that's quite a delightful surprise! Honey is such a versatile and beneficial food, with a rich, sweet taste \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthat's hard to resist. In our conversation, you had mentioned enjoying ice cream, and I had associated that with \u001b[0m\n",
       "\u001b[1;38;2;118;185;0myour favorite food. But it turns out, your favorite is the all-natural, golden sweetness of honey! I'm glad we got \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthat cleared up, and now I know a bit more about your preferences. Thank you for sharing that with me!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Absolutely, I do! After our little chat, I found out that your favorite food is indeed honey. I apologize for the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">misunderstanding earlier, but I'm glad we got that cleared up. Honey really is a wonderful choice with its unique </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">taste and natural benefits. Thanks again for sharing that with me!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAbsolutely, I do! After our little chat, I found out that your favorite food is indeed honey. I apologize for the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmisunderstanding earlier, but I'm glad we got that cleared up. Honey really is a wonderful choice with its unique \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtaste and natural benefits. Thanks again for sharing that with me!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "########################################################################\n",
    "## Reset knowledge base and define what it means to add more messages.\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([f\"User said {d.get('input')}\", f\"Agent said {d.get('output')}\"])\n",
    "    return d.get('output')\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    "    \"\\nAnswer the user conversationally. Make sure the conversation flows naturally.\\n\"\n",
    "    \"[Agent]\"\n",
    ")\n",
    "\n",
    "\n",
    "conv_chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'input': (lambda x:x)\n",
    "    }\n",
    "    | RunnableAssign({'output' : chat_prompt | instruct_llm | StrOutputParser()})\n",
    "    | partial(save_memory_and_get_output, vstore=convstore)\n",
    ")\n",
    "\n",
    "pprint(conv_chain.invoke(\"I'm glad you agree! I can't wait to get some ice cream there! It's such a good food!\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Can you guess what my favorite food is?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Actually, my favorite is honey! Not sure where you got that idea?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"I see! Fair enough! Do you know my favorite food now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KRMW6G7NVSWF",
   "metadata": {
    "id": "KRMW6G7NVSWF"
   },
   "source": [
    "Unlike the more automatic full-text or rule-based approaches to injecting context into the LLM, this approach ensures some amount of consolidation which can keep the context length from getting out of hand. It's still not a full-proof strategy on its own, but it's a stark improvement for unstructured conversations (and doesn't even require a strong instruction-tuned model to perform slot-filling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9TPkh3SaLbqh",
   "metadata": {
    "id": "9TPkh3SaLbqh"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 3 [Exercise]:** RAG For Document Chunk Retrieval\n",
    "\n",
    "Given our prior exploration of document loading, the idea that data chunks can be embedded and searched through probably isn't surprising. With that said, it is definitely worth going over since applying RAG with documents is a double-edged sword; it may **seem** to work well out of the box but requires some extra care when optimizing it for truly reliable performance. It also provides an excellent opportunity to review some fundamental LCEL skills, so let's see what we can do!\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Exercise:**\n",
    "\n",
    "In the previous example, you may recall that we pulled in some relatively small papers with the help of [`ArxivLoader`](https://python.langchain.com/docs/integrations/document_loaders/arxiv) using the following syntax:\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "docs = [\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL\n",
    "    ArxivLoader(query=\"2210.03629\").load(),  ## ReAct\n",
    "]\n",
    "```\n",
    "\n",
    "Given all that you've learned so far, choose a selection of papers that you would like to use and develop a chatbot that can talk about them!\n",
    "\n",
    "<br>\n",
    "\n",
    "Though this is a pretty big task, a walkthrough of ***most*** of the process will be provided below. By the end of the walkthrough, many of the necessary puzzle pieces will be provided, and your real task will be to integrate them together for the final `retrieval_chain`. When you're done, get ready to re-integrate the chain (or a flavor of your choice) in the last notebook as part of the evaluation exercise!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jSjfCtiQnj9e",
   "metadata": {
    "id": "jSjfCtiQnj9e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 1**: Loading And Chunking Your Documents\n",
    "\n",
    "The following code block gives you some default papers to load in for your RAG chain. Feel free to select more papers as desired, but note that longer documents will take longer to process. A few simplifying assumptions and additional processing steps are included to help you improve your naive RAG performance:\n",
    "\n",
    "- Documents are cut off prior to the \"References\" section if one exists. This will keep our system from considering the citations and appendix sections, which tend to be long and distracting.\n",
    "\n",
    "- A chunk that lists the available documents is inserted to provide a high-level view of all available documents in a single chunk. If your pipeline does not provide metadata on each retrieval, this is a useful component and can even be listed among a list of higher-priority pieces if appropriate.\n",
    "\n",
    "- Additionally, the metadata entries are also inserted to provide general information. Ideally, there would also be some synthetic chunks that merge the metadata into interesting cross-document chunks.\n",
    "\n",
    "**NOTE:** ***For the sake of the assessment, please include at least one paper that is less than one month old!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "S-3FBdT_lhVT",
   "metadata": {
    "id": "S-3FBdT_lhVT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents\n",
      "Chunking Documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Available Documents:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Agentic Privacy-Preserving Machine Learning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Measuring the Impact of Early-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> AI on Experienced Open-Source Developer Productivity</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAvailable Documents:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Agentic Privacy-Preserving Machine Learning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Measuring the Impact of Early-\u001b[0m\u001b[1;36m2025\u001b[0m\u001b[1;38;2;118;185;0m AI on Experienced Open-Source Developer Productivity\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      " - # Chunks: 31\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-30'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Agentic Privacy-Preserving Machine Learning'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Mengyu Zhang, Zhuotao Liu, Jingwen Huang, Xuanqi Liu'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Privacy-preserving machine learning (PPML) is critical to ensure data privacy\\nin AI. Over the past</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">few years, the community has proposed a wide range of\\nprovably secure PPML schemes that rely on various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cryptography primitives.\\nHowever, when it comes to large language models (LLMs) with billions of\\nparameters, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency of PPML is everything but acceptable. For instance,\\nthe state-of-the-art solution for confidential LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference represents at\\nleast 10,000-fold slower performance compared to plaintext inference. The\\nperformance gap</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is even larger when the context length increases. In this\\nposition paper, we propose a novel framework named </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Agentic-PPML to make PPML in\\nLLMs practical. Our key insight is to employ a general-purpose LLM for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intent\\nunderstanding and delegate cryptographically secure inference to specialized\\nmodels trained on vertical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">domains. By modularly separating language intent\\nparsing - which typically involves little or no sensitive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information - from\\nprivacy-critical computation, Agentic-PPML completely eliminates the need for\\nthe LLMs to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process the encrypted prompts, enabling practical deployment of\\nprivacy-preserving LLM-centric services.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-07-30'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Agentic Privacy-Preserving Machine Learning'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Mengyu Zhang, Zhuotao Liu, Jingwen Huang, Xuanqi Liu'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Privacy-preserving machine learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPPML\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is critical to ensure data privacy\\nin AI. Over the past\u001b[0m\n",
       "\u001b[32mfew years, the community has proposed a wide range of\\nprovably secure PPML schemes that rely on various \u001b[0m\n",
       "\u001b[32mcryptography primitives.\\nHowever, when it comes to large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with billions of\\nparameters, the \u001b[0m\n",
       "\u001b[32mefficiency of PPML is everything but acceptable. For instance,\\nthe state-of-the-art solution for confidential LLM \u001b[0m\n",
       "\u001b[32minference represents at\\nleast 10,000-fold slower performance compared to plaintext inference. The\\nperformance gap\u001b[0m\n",
       "\u001b[32mis even larger when the context length increases. In this\\nposition paper, we propose a novel framework named \u001b[0m\n",
       "\u001b[32mAgentic-PPML to make PPML in\\nLLMs practical. Our key insight is to employ a general-purpose LLM for \u001b[0m\n",
       "\u001b[32mintent\\nunderstanding and delegate cryptographically secure inference to specialized\\nmodels trained on vertical \u001b[0m\n",
       "\u001b[32mdomains. By modularly separating language intent\\nparsing - which typically involves little or no sensitive \u001b[0m\n",
       "\u001b[32minformation - from\\nprivacy-critical computation, Agentic-PPML completely eliminates the need for\\nthe LLMs to \u001b[0m\n",
       "\u001b[32mprocess the encrypted prompts, enabling practical deployment of\\nprivacy-preserving LLM-centric services.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1\n",
      " - # Chunks: 78\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-08-05'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Fangyi Yu'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'As large language models (LLMs) grow in capability and autonomy, evaluating\\ntheir </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs-especially in open-ended and complex tasks-has become a critical\\nbottleneck. A new paradigm is emerging: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using AI agents as the evaluators\\nthemselves. This \"agent-as-a-judge\" approach leverages the reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\nperspective-taking abilities of LLMs to assess the quality and safety of other\\nmodels, promising calable and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nuanced alternatives to human evaluation. In this\\nreview, we define the agent-as-a-judge concept, trace its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evolution from\\nsingle-model judges to dynamic multi-agent debate frameworks, and critically\\nexamine their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strengths and shortcomings. We compare these approaches across\\nreliability, cost, and human alignment, and survey </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">real-world deployments in\\ndomains such as medicine, law, finance, and education. Finally, we highlight\\npressing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenges-including bias, robustness, and meta evaluation-and outline\\nfuture research directions. By bringing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">together these strands, our review\\ndemonstrates how agent-based judging can complement (but not replace) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human\\noversight, marking a step toward trustworthy, scalable evaluation for\\nnext-generation LLMs.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-08-05'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Fangyi Yu'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'As large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m grow in capability and autonomy, evaluating\\ntheir \u001b[0m\n",
       "\u001b[32moutputs-especially in open-ended and complex tasks-has become a critical\\nbottleneck. A new paradigm is emerging: \u001b[0m\n",
       "\u001b[32musing AI agents as the evaluators\\nthemselves. This \"agent-as-a-judge\" approach leverages the reasoning \u001b[0m\n",
       "\u001b[32mand\\nperspective-taking abilities of LLMs to assess the quality and safety of other\\nmodels, promising calable and \u001b[0m\n",
       "\u001b[32mnuanced alternatives to human evaluation. In this\\nreview, we define the agent-as-a-judge concept, trace its \u001b[0m\n",
       "\u001b[32mevolution from\\nsingle-model judges to dynamic multi-agent debate frameworks, and critically\\nexamine their \u001b[0m\n",
       "\u001b[32mstrengths and shortcomings. We compare these approaches across\\nreliability, cost, and human alignment, and survey \u001b[0m\n",
       "\u001b[32mreal-world deployments in\\ndomains such as medicine, law, finance, and education. Finally, we highlight\\npressing \u001b[0m\n",
       "\u001b[32mchallenges-including bias, robustness, and meta evaluation-and outline\\nfuture research directions. By bringing \u001b[0m\n",
       "\u001b[32mtogether these strands, our review\\ndemonstrates how agent-based judging can complement \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbut not replace\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhuman\\noversight, marking a step toward trustworthy, scalable evaluation for\\nnext-generation LLMs.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 2\n",
      " - # Chunks: 41\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-08-05'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Peng Ding, Rick Stevens'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The proliferation of tool-augmented Large Language Models (LLMs) has created\\na fragmented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ecosystem where developers must navigate multiple protocols,\\nmanual schema definitions, and complex execution </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">workflows. We address this\\nchallenge by proposing a unified approach to tool integration that abstracts\\nprotocol </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">differences while optimizing execution performance. Our solution\\ndemonstrates how protocol-agnostic design </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">principles can significantly reduce\\ndevelopment overhead through automated schema generation, dual-mode </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concurrent\\nexecution, and seamless multi-source tool management. Experimental results show\\n60-80% code reduction </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across integration scenarios, performance improvements up\\nto 3.1x through optimized concurrency, and full </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compatibility with existing\\nfunction calling standards. This work contributes both theoretical insights\\ninto tool</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">integration architecture and practical solutions for real-world LLM\\napplication development.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-08-05'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Peng Ding, Rick Stevens'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'The proliferation of tool-augmented Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has created\\na fragmented \u001b[0m\n",
       "\u001b[32mecosystem where developers must navigate multiple protocols,\\nmanual schema definitions, and complex execution \u001b[0m\n",
       "\u001b[32mworkflows. We address this\\nchallenge by proposing a unified approach to tool integration that abstracts\\nprotocol \u001b[0m\n",
       "\u001b[32mdifferences while optimizing execution performance. Our solution\\ndemonstrates how protocol-agnostic design \u001b[0m\n",
       "\u001b[32mprinciples can significantly reduce\\ndevelopment overhead through automated schema generation, dual-mode \u001b[0m\n",
       "\u001b[32mconcurrent\\nexecution, and seamless multi-source tool management. Experimental results show\\n60-80% code reduction \u001b[0m\n",
       "\u001b[32macross integration scenarios, performance improvements up\\nto 3.1x through optimized concurrency, and full \u001b[0m\n",
       "\u001b[32mcompatibility with existing\\nfunction calling standards. This work contributes both theoretical insights\\ninto tool\u001b[0m\n",
       "\u001b[32mintegration architecture and practical solutions for real-world LLM\\napplication development.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 3\n",
      " - # Chunks: 46\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-25'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Joel Becker, Nate Rush, Elizabeth Barnes, David Rein'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Despite widespread adoption, the impact of AI tools on software development\\nin the wild remains </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understudied. We conduct a randomized controlled trial\\n(RCT) to understand how AI tools at the February-June 2025 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">frontier affect the\\nproductivity of experienced open-source developers. 16 developers with moderate\\nAI experience</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complete 246 tasks in mature projects on which they have an\\naverage of 5 years of prior experience. Each task is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">randomly assigned to allow\\nor disallow usage of early 2025 AI tools. When AI tools are allowed, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">developers\\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.\\nBefore starting tasks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">developers forecast that allowing AI will reduce\\ncompletion time by 24%. After completing the study, developers </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimate that\\nallowing AI reduced completion time by 20%. Surprisingly, we find that allowing\\nAI actually </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">increases completion time by 19%--AI tooling slowed developers\\ndown. This slowdown also contradicts predictions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from experts in economics (39%\\nshorter) and ML (38% shorter). To understand this result, we collect and\\nevaluate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evidence for 20 properties of our setting that a priori could\\ncontribute to the observed slowdown effect--for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">example, the size and quality\\nstandards of projects, or prior developer experience with AI tooling. Although\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">influence of experimental artifacts cannot be entirely ruled out, the\\nrobustness of the slowdown effect across our</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">analyses suggests it is unlikely\\nto primarily be a function of our experimental design.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-07-25'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Joel Becker, Nate Rush, Elizabeth Barnes, David Rein'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Despite widespread adoption, the impact of AI tools on software development\\nin the wild remains \u001b[0m\n",
       "\u001b[32munderstudied. We conduct a randomized controlled trial\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mRCT\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to understand how AI tools at the February-June 2025 \u001b[0m\n",
       "\u001b[32mfrontier affect the\\nproductivity of experienced open-source developers. 16 developers with moderate\\nAI experience\u001b[0m\n",
       "\u001b[32mcomplete 246 tasks in mature projects on which they have an\\naverage of 5 years of prior experience. Each task is \u001b[0m\n",
       "\u001b[32mrandomly assigned to allow\\nor disallow usage of early 2025 AI tools. When AI tools are allowed, \u001b[0m\n",
       "\u001b[32mdevelopers\\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.\\nBefore starting tasks, \u001b[0m\n",
       "\u001b[32mdevelopers forecast that allowing AI will reduce\\ncompletion time by 24%. After completing the study, developers \u001b[0m\n",
       "\u001b[32mestimate that\\nallowing AI reduced completion time by 20%. Surprisingly, we find that allowing\\nAI actually \u001b[0m\n",
       "\u001b[32mincreases completion time by 19%--AI tooling slowed developers\\ndown. This slowdown also contradicts predictions \u001b[0m\n",
       "\u001b[32mfrom experts in economics \u001b[0m\u001b[32m(\u001b[0m\u001b[32m39%\\nshorter\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and ML \u001b[0m\u001b[32m(\u001b[0m\u001b[32m38% shorter\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To understand this result, we collect and\\nevaluate \u001b[0m\n",
       "\u001b[32mevidence for 20 properties of our setting that a priori could\\ncontribute to the observed slowdown effect--for \u001b[0m\n",
       "\u001b[32mexample, the size and quality\\nstandards of projects, or prior developer experience with AI tooling. Although\\nthe \u001b[0m\n",
       "\u001b[32minfluence of experimental artifacts cannot be entirely ruled out, the\\nrobustness of the slowdown effect across our\u001b[0m\n",
       "\u001b[32manalyses suggests it is unlikely\\nto primarily be a function of our experimental design.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 4\n",
      " - # Chunks: 51\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-03'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Edan Toledo, Karen Hambardzumyan, Martin Josifoski, Rishi Hazra, Nicolas Baldwin, Alexis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Audran-Reiss, Michael Kuchnik, Despoina Magka, Minqi Jiang, Alisia Maria Lupidi, Andrei Lupu, Roberta Raileanu, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kelvin Niu, Tatiana Shavrina, Jean-Christophe Gagnon-Audet, Michael Shvartsman, Shagun Sodhani, Alexander H. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Miller, Abhishek Charnalia, Derek Dunfield, Carole-Jean Wu, Pontus Stenetorp, Nicola Cancedda, Jakob Nicolaus </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Foerster, Yoram Bachrach'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"AI research agents are demonstrating great potential to accelerate scientific\\nprogress by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">automating the design, implementation, and training of machine\\nlearning models. We focus on methods for improving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents' performance on\\nMLE-bench, a challenging benchmark where agents compete in Kaggle competitions\\nto solve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">real-world machine learning problems. We formalize AI research agents\\nas search policies that navigate a space of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">candidate solutions, iteratively\\nmodifying them using operators. By designing and systematically </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">varying\\ndifferent operator sets and search policies (Greedy, MCTS, Evolutionary), we\\nshow that their interplay is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">critical for achieving high performance. Our best\\npairing of search strategy and operator set achieves a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">state-of-the-art result\\non MLE-bench lite, increasing the success rate of achieving a Kaggle medal from\\n39.6% to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">47.7%. Our investigation underscores the importance of jointly\\nconsidering the search strategy, operator design, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and evaluation methodology in\\nadvancing automated machine learning.\"</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2025-07-03'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Edan Toledo, Karen Hambardzumyan, Martin Josifoski, Rishi Hazra, Nicolas Baldwin, Alexis \u001b[0m\n",
       "\u001b[32mAudran-Reiss, Michael Kuchnik, Despoina Magka, Minqi Jiang, Alisia Maria Lupidi, Andrei Lupu, Roberta Raileanu, \u001b[0m\n",
       "\u001b[32mKelvin Niu, Tatiana Shavrina, Jean-Christophe Gagnon-Audet, Michael Shvartsman, Shagun Sodhani, Alexander H. \u001b[0m\n",
       "\u001b[32mMiller, Abhishek Charnalia, Derek Dunfield, Carole-Jean Wu, Pontus Stenetorp, Nicola Cancedda, Jakob Nicolaus \u001b[0m\n",
       "\u001b[32mFoerster, Yoram Bachrach'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"AI research agents are demonstrating great potential to accelerate scientific\\nprogress by \u001b[0m\n",
       "\u001b[32mautomating the design, implementation, and training of machine\\nlearning models. We focus on methods for improving \u001b[0m\n",
       "\u001b[32magents' performance on\\nMLE-bench, a challenging benchmark where agents compete in Kaggle competitions\\nto solve \u001b[0m\n",
       "\u001b[32mreal-world machine learning problems. We formalize AI research agents\\nas search policies that navigate a space of \u001b[0m\n",
       "\u001b[32mcandidate solutions, iteratively\\nmodifying them using operators. By designing and systematically \u001b[0m\n",
       "\u001b[32mvarying\\ndifferent operator sets and search policies \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGreedy, MCTS, Evolutionary\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, we\\nshow that their interplay is\u001b[0m\n",
       "\u001b[32mcritical for achieving high performance. Our best\\npairing of search strategy and operator set achieves a \u001b[0m\n",
       "\u001b[32mstate-of-the-art result\\non MLE-bench lite, increasing the success rate of achieving a Kaggle medal from\\n39.6% to \u001b[0m\n",
       "\u001b[32m47.7%. Our investigation underscores the importance of jointly\\nconsidering the search strategy, operator design, \u001b[0m\n",
       "\u001b[32mand evaluation methodology in\\nadvancing automated machine learning.\"\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \"],\n",
    ")\n",
    "\n",
    "## TODO: Please pick some papers and add them to the list as you'd like\n",
    "## NOTE: To re-use for the final assessment, make sure at least one paper is < 1 month old\n",
    "print(\"Loading Documents\")\n",
    "docs = [\n",
    "    ArxivLoader(query=\"2508.02836\").load(),  ## Agentic Privacy-Preserving Machine Learning (July 30, 2025)\n",
    "    ArxivLoader(query=\"2508.02994\").load(),  ## When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs (Aug 2025)\n",
    "    ArxivLoader(query=\"2508.02979\").load(),  ## Unified Tool Integration for LLMs: A Protocol-Agnostic Approach (Aug 2025)\n",
    "    ArxivLoader(query=\"2507.09089\").load(),  ## Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity (July 2025)\n",
    "    ArxivLoader(query=\"2507.02554\").load(),  ## AI Research Agents for Machine Learning: Search, Exploration, and Generalization (July 3, 2025)\n",
    "    \n",
    "    # ArxivLoader(query=\"1706.03762\").load(),  ## Attention Is All You Need Paper\n",
    "    # ArxivLoader(query=\"1810.04805\").load(),  ## BERT Paper\n",
    "    # ArxivLoader(query=\"2005.11401\").load(),  ## RAG Paper\n",
    "    # ArxivLoader(query=\"2205.00445\").load(),  ## MRKL Paper\n",
    "    # ArxivLoader(query=\"2310.06825\").load(),  ## Mistral Paper\n",
    "    # ArxivLoader(query=\"2306.05685\").load(),  ## LLM-as-a-Judge\n",
    "    ## Some longer papers\n",
    "    # ArxivLoader(query=\"2210.03629\").load(),  ## ReAct Paper\n",
    "    # ArxivLoader(query=\"2112.10752\").load(),  ## Latent Stable Diffusion Paper\n",
    "    # ArxivLoader(query=\"2103.00020\").load(),  ## CLIP Paper\n",
    "    ## TODO: Feel free to add more\n",
    "]\n",
    "\n",
    "## Cut the paper short if references is included.\n",
    "## This is a standard string in papers.\n",
    "for doc in docs:\n",
    "    content = json.dumps(doc[0].page_content)\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "## Split the documents and also filter out stubs (overly short chunks)\n",
    "print(\"Chunking Documents\")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata.get('Title')\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "\n",
    "## Printing out some summary information for reference\n",
    "pprint(doc_string, '\\n')\n",
    "for i, chunks in enumerate(docs_chunks):\n",
    "    print(f\"Document {i}\")\n",
    "    print(f\" - # Chunks: {len(chunks)}\")\n",
    "    print(f\" - Metadata: \")\n",
    "    pprint(chunks[0].metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4pWU_OOnnrsT",
   "metadata": {
    "id": "4pWU_OOnnrsT"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 2**: Construct Your Document Vector Stores\n",
    "\n",
    "Now that we have all of the components, we can go ahead and create indices surrounding them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lwwmr3aptwCg",
   "metadata": {
    "id": "lwwmr3aptwCg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: user 598 ms, sys: 17.9 ms, total: 616 ms\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embedder)]\n",
    "vecstores += [FAISS.from_documents(doc_chunks, embedder) for doc_chunks in docs_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j39JwCKubto0",
   "metadata": {
    "id": "j39JwCKubto0"
   },
   "source": [
    "<br>\n",
    "\n",
    "From there, we can combine our indices into a single one using the following utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Q7us66iPVc70",
   "metadata": {
    "id": "Q7us66iPVc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed aggregate docstore with 253 chunks\n"
     ]
    }
   ],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embed_dims = len(embedder.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embedder,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    ## We'll use default_faiss for simplicity, though it's tied to your embedder by reference\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "## Unintuitive optimization; merge_from seems to optimize constituent vector stores away\n",
    "docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VU_VEx2mqJUK",
   "metadata": {
    "id": "VU_VEx2mqJUK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 3: [Exercise]** Implement Your RAG Chain\n",
    "\n",
    "Finally, all the puzzle pieces are in place to implement the RAG pipeline! As a review, we now have:\n",
    "\n",
    "- A way to construct a from-scratch vector store for conversational memory (and a way to initialize an empty one with `default_FAISS()`)\n",
    "\n",
    "- A vector store pre-loaded with useful document information from our `ArxivLoader` utility (stored in `docstore`).\n",
    "\n",
    "With the help of a couple more utilities, you're finally ready to integrate your chain! A few additional convenience utilities are provided (`doc2str` and the now-common `RPrint`) but are optional to use. Additionally, some starter prompts and structures are also defined.\n",
    "\n",
    "> **Given all of this:** Please implement the `retrieval_chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "-RXSrb1GcNff",
   "metadata": {
    "id": "-RXSrb1GcNff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: Tell me about RAG!\\n\\n From this, we have retrieved the following potentially-useful info:  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conversation History Retrieval:\\n\\n\\n Document Retrieval:\\n[Quote from AI Research Agents for Machine Learning: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Search, Exploration, and Generalization in MLE-bench] ., 2025), a benchmark\\\\nwhere AI agents compete in Kaggle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">competitions\\\\n1o1-preview is deprecated.\\\\n1\\\\n(1)\\\\u00a0\\\\nSelect </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Node(s)\\\\n(3)\\\\nEvaluation\\\\nSearch\\\\nCode\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n7\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n6\\\\nOperators\\\\n...\\\\nDraft\\\\nDebug\\\\nImprove\\\\nScore\\\\nInvalid\\\\nLow\\\\nHigh\\\\n\\\\u00a0\\\\nState\\\\n(2)\\\\u00a0\\\\nSel</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ect &amp; Apply\\\\nOperator\\\\nRepeat\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n7\\\\nFigure 2 Overview of AIRA. Given a problem </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specification, AIRA maintains a search graph whose nodes are (partial)\\\\nsolutions. At each iteration, the agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(1) selects nodes via a selection policy, (2) picks an operator via an operator\\\\npolicy and applies this operator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to the node, and (3) scores the resulting solution via a fitness function. Here, a greedy\\\\nnode-selection strategy</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applies the improve operator to the highest-scoring node.\\\\nto solve real-world machine learning (ML) problems. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Notably, the state-of-the-art approach AIDE (Jiang et al\\n[Quote from AI Research Agents for Machine Learning: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Search, Exploration, and Generalization in MLE-bench] . Notably, the state-of-the-art approach AIDE (Jiang et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al.,\\\\n2025) does not fully disentangle these performance factors, providing limited insight into which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components\\\\nprimarily drive the agent\\\\u2019s performance and where improvements are needed.\\\\nWe start by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">formalizing the design of AI research agents as a search algorithm composed of two components: The\\\\nfirst one is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the search policy which is used to navigate the space of candidate solutions, and the second is the\\\\noperators </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which iteratively modifies existing solutions to generate new candidate solutions. In this framework\\\\n(Fig. 2), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AIDE is represented as a greedy search algorithm that, at each step, applies one of its code operators\\\\n(i.e., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Draft, Debug, Improve) to the current best solution. This allows us to disentangle the effect of the\\\\nsearch from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that of the operators\\n[Quote from AI Research Agents for Machine Learning: Search, Exploration, and Generalization</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in MLE-bench] .\\\\nThis combination of \\\\u03c0sel, \\\\u03c0op, and OAIDE defines the baseline agent we denote </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AIDEgreedy (also summarized\\\\nin Appendix B). When the agent uses an alternative search policy while keeping OAIDE </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unchanged, we write\\\\nAIDEsearch_policy to identify change. For example, AIDEmcts uses the AIDE operator set and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MCTS as the\\\\nsearch policy.\\\\n3\\\\nExperiment Design\\\\n3.1\\\\nAIRA-dojo\\\\nAn agent\\\\u2019s environment greatly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">influences its performance. To systematically study the space of agentic policies\\\\n(see Fig. 7), we introduce the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AI Research Agent (AIRA) dojo\\\\u2014a scalable and customizable framework for AI\\\\nresearch agents. AIRA-dojo </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provides the environment in which agents operate, along with abstractions for\\\\noperators and policies as described</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Section 2, and tasks that define evaluation criteria for agent performance\\n[Quote from AI Research Agents for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Machine Learning: Search, Exploration, and Generalization in MLE-bench] . Superimage, a container image, provides a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">base set of tools required for common ML tasks.\\\\nThis image includes pre-configured CUDA support, key deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning frameworks such as PyTorch and\\\\nTensorFlow, and essential data science libraries. Each coding session </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">starts from the original Superimage\\\\nstate and can diverge based on the agent\\\\u2019s actions while not affecting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the state of the other agents.\\\\nTogether, these design choices create a stable and robust testbed that eliminates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">confounders at both the\\\\nsystem and implementation levels. This reliability enables reproducible benchmarking and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facilitates the\\\\ndevelopment of long-running agentic systems across thousands of parallel runs and diverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\\\n3.3\\\\nMLE-bench\\\\nMLE-bench (Chan et al., 2025) comprises of 75 tasks sourced from Kaggle, designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assess the capabilities\\\\nof agents in machine learning engineering\\n\\n\\n (Answer only from retrieval. Only cite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sources that are used. Make your response conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Tell me about RAG!'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={})</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: Tell me about RAG!\\n\\n From this, we have retrieved the following potentially-useful info:  \u001b[0m\n",
       "\u001b[32mConversation History Retrieval:\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from AI Research Agents for Machine Learning: \u001b[0m\n",
       "\u001b[32mSearch, Exploration, and Generalization in MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m ., 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a benchmark\\\\nwhere AI agents compete in Kaggle \u001b[0m\n",
       "\u001b[32mcompetitions\\\\n1o1-preview is deprecated.\\\\n1\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\u00a0\\\\nSelect \u001b[0m\n",
       "\u001b[32mNode\u001b[0m\u001b[32m(\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nEvaluation\\\\nSearch\\\\nCode\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n7\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\u001b[0m\n",
       "\u001b[32m\\n6\\\\nOperators\\\\n...\\\\nDraft\\\\nDebug\\\\nImprove\\\\nScore\\\\nInvalid\\\\nLow\\\\nHigh\\\\n\\\\u00a0\\\\nState\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\u00a0\\\\nSel\u001b[0m\n",
       "\u001b[32mect & Apply\\\\nOperator\\\\nRepeat\\\\n1\\\\n2\\\\n3\\\\n4\\\\n5\\\\n6\\\\n7\\\\nFigure 2 Overview of AIRA. Given a problem \u001b[0m\n",
       "\u001b[32mspecification, AIRA maintains a search graph whose nodes are \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpartial\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\nsolutions. At each iteration, the agent \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m selects nodes via a selection policy, \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m picks an operator via an operator\\\\npolicy and applies this operator \u001b[0m\n",
       "\u001b[32mto the node, and \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m scores the resulting solution via a fitness function. Here, a greedy\\\\nnode-selection strategy\u001b[0m\n",
       "\u001b[32mapplies the improve operator to the highest-scoring node.\\\\nto solve real-world machine learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mML\u001b[0m\u001b[32m)\u001b[0m\u001b[32m problems. \u001b[0m\n",
       "\u001b[32mNotably, the state-of-the-art approach AIDE \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJiang et al\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from AI Research Agents for Machine Learning: \u001b[0m\n",
       "\u001b[32mSearch, Exploration, and Generalization in MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Notably, the state-of-the-art approach AIDE \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJiang et \u001b[0m\n",
       "\u001b[32mal.,\\\\n2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m does not fully disentangle these performance factors, providing limited insight into which \u001b[0m\n",
       "\u001b[32mcomponents\\\\nprimarily drive the agent\\\\u2019s performance and where improvements are needed.\\\\nWe start by \u001b[0m\n",
       "\u001b[32mformalizing the design of AI research agents as a search algorithm composed of two components: The\\\\nfirst one is \u001b[0m\n",
       "\u001b[32mthe search policy which is used to navigate the space of candidate solutions, and the second is the\\\\noperators \u001b[0m\n",
       "\u001b[32mwhich iteratively modifies existing solutions to generate new candidate solutions. In this framework\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mFig. 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mAIDE is represented as a greedy search algorithm that, at each step, applies one of its code operators\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mi.e., \u001b[0m\n",
       "\u001b[32mDraft, Debug, Improve\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to the current best solution. This allows us to disentangle the effect of the\\\\nsearch from \u001b[0m\n",
       "\u001b[32mthat of the operators\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from AI Research Agents for Machine Learning: Search, Exploration, and Generalization\u001b[0m\n",
       "\u001b[32min MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m .\\\\nThis combination of \\\\u03c0sel, \\\\u03c0op, and OAIDE defines the baseline agent we denote \u001b[0m\n",
       "\u001b[32mAIDEgreedy \u001b[0m\u001b[32m(\u001b[0m\u001b[32malso summarized\\\\nin Appendix B\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. When the agent uses an alternative search policy while keeping OAIDE \u001b[0m\n",
       "\u001b[32munchanged, we write\\\\nAIDEsearch_policy to identify change. For example, AIDEmcts uses the AIDE operator set and \u001b[0m\n",
       "\u001b[32mMCTS as the\\\\nsearch policy.\\\\n3\\\\nExperiment Design\\\\n3.1\\\\nAIRA-dojo\\\\nAn agent\\\\u2019s environment greatly \u001b[0m\n",
       "\u001b[32minfluences its performance. To systematically study the space of agentic policies\\\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Fig. 7\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, we introduce the \u001b[0m\n",
       "\u001b[32mAI Research Agent \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAIRA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m dojo\\\\u2014a scalable and customizable framework for AI\\\\nresearch agents. AIRA-dojo \u001b[0m\n",
       "\u001b[32mprovides the environment in which agents operate, along with abstractions for\\\\noperators and policies as described\u001b[0m\n",
       "\u001b[32min Section 2, and tasks that define evaluation criteria for agent performance\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from AI Research Agents for \u001b[0m\n",
       "\u001b[32mMachine Learning: Search, Exploration, and Generalization in MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Superimage, a container image, provides a\u001b[0m\n",
       "\u001b[32mbase set of tools required for common ML tasks.\\\\nThis image includes pre-configured CUDA support, key deep \u001b[0m\n",
       "\u001b[32mlearning frameworks such as PyTorch and\\\\nTensorFlow, and essential data science libraries. Each coding session \u001b[0m\n",
       "\u001b[32mstarts from the original Superimage\\\\nstate and can diverge based on the agent\\\\u2019s actions while not affecting \u001b[0m\n",
       "\u001b[32mthe state of the other agents.\\\\nTogether, these design choices create a stable and robust testbed that eliminates \u001b[0m\n",
       "\u001b[32mconfounders at both the\\\\nsystem and implementation levels. This reliability enables reproducible benchmarking and \u001b[0m\n",
       "\u001b[32mfacilitates the\\\\ndevelopment of long-running agentic systems across thousands of parallel runs and diverse \u001b[0m\n",
       "\u001b[32mtasks.\\\\n3.3\\\\nMLE-bench\\\\nMLE-bench \u001b[0m\u001b[32m(\u001b[0m\u001b[32mChan et al., 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m comprises of 75 tasks sourced from Kaggle, designed to \u001b[0m\n",
       "\u001b[32massess the capabilities\\\\nof agents in machine learning engineering\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from retrieval. Only cite \u001b[0m\n",
       "\u001b[32msources that are used. Make your response conversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Tell me about RAG!'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG seems to refer to a concept from the document \"AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench\" from the year 2025. However, the document does not provide a clear definition or explanation of RAG on its own. I had to make some assumptions based on the context provided.\n",
      "\n",
      "From what I can gather, RAG might be an acronym for \"Reinforcement Agent in Graph,\" which is a hypothetical concept introduced in the document. This concept is used to describe a type of AI research agent that operates within a search graph, where nodes represent (partial) solutions to a given problem.\n",
      "\n",
      "In this context, RAG maintains a search graph whose nodes are candidate solutions, and at each iteration, the agent selects nodes via a selection policy, picks an operator via an operator policy, and scores the resulting solution via a fitness function.\n",
      "\n",
      "The document mentions RAG as a part of the AIRA (AI Research Agent) framework, which is designed to solve real-world machine learning problems by searching and iteratively modifying existing solutions to generate new candidate solutions.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench. (2025). Retrieved from [Quote from AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench]"
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import gradio as gr\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
    "# instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "stream_chain = chat_prompt| RPrint() | instruct_llm | StrOutputParser()\n",
    "\n",
    "################################################################################################\n",
    "## BEGIN TODO: Implement the retrieval chain to make your system work!\n",
    "\n",
    "# Long context reorder utility\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input': (lambda x: x)}\n",
    "    ## TODO: Make sure to retrieve history & context from convstore & docstore, respectively.\n",
    "    ## HINT: Our solution uses RunnableAssign, itemgetter, long_reorder, and docs2str\n",
    "    | RunnableAssign({\n",
    "        'history': itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str\n",
    "    })\n",
    "    | RunnableAssign({\n",
    "        'context': itemgetter('input') | docstore.as_retriever() | long_reorder | docs2str  \n",
    "    })\n",
    ")\n",
    "\n",
    "## END TODO\n",
    "################################################################################################\n",
    "\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    ## First perform the retrieval based on the input message\n",
    "    retrieval = retrieval_chain.invoke(message)\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(retrieval):\n",
    "        buffer += token\n",
    "        ## If you're using standard print, keep line from getting too long\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "\n",
    "## Start of Agent Event Loop\n",
    "test_question = \"Tell me about RAG!\"  ## <- modify as desired\n",
    "\n",
    "## Before you launch your gradio interface, make sure your thing works\n",
    "for response in chat_gen(test_question, return_buffer=False):\n",
    "    print(response, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9W7sC5Z6BfqM",
   "metadata": {
    "id": "9W7sC5Z6BfqM"
   },
   "source": [
    "### **Task 4:** Interact With Your Gradio Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fMP3l7QL2JWT",
   "metadata": {
    "id": "fMP3l7QL2JWT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.41.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://4160273c296fb96210.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4160273c296fb96210.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">messages</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'You are a document chatbot. Help the user as they ask questions about documents. User messaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just asked: tell me a cool fact\\n\\n From this, we have retrieved the following potentially-useful info:  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conversation History Retrieval:\\n[Quote from Document] Agent previously responded with RAG seems to refer to a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept from the document \"AI Research Agents for Machine Learning: Search, Exploration, and Generalization in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MLE-bench\" from the year 2025. However, the document does not provide a clear definition or explanation of RAG on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its own. I had to make some assumptions based on the context provided.\\n\\nFrom what I can gather, RAG might be an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">acronym for \"Reinforcement Agent in Graph,\" which is a hypothetical concept introduced in the document. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept is used to describe a type of AI research agent that operates within a search graph, where nodes represent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(partial) solutions to a given problem.\\n\\nIn this context, RAG maintains a search graph whose nodes are candidate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solutions, and at each iteration, the agent selects nodes via a selection policy, picks an operator via an operator</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">policy, and scores the resulting solution via a fitness function.\\n\\nThe document mentions RAG as a part of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AIRA (AI Research Agent) framework, which is designed to solve real-world machine learning problems by searching </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and iteratively modifying existing solutions to generate new candidate solutions.\\n\\nSources:\\n\\n* AI Research </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench. (2025). Retrieved from [Quote </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench]\\n[Quote from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Document] User previously responded with Tell me about RAG!\\n\\n\\n Document Retrieval:\\n[Quote from When AIs Judge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs] .\\\\n\\\\u2022 Integrating Tool Use in Judges: Agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">judges\\\\nthat can use tools (like search engines, code\\\\ninterpreters, calculators) will become more\\\\nimportant as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks get complex or require live\\\\ndata verification. We might see hybrid evalua-\\\\ntor agents: for example, an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent that, when\\\\nevaluating a factual answer, automatically\\\\nconsults a knowledge base or the web to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fact-\\\\ncheck statements. This would dramatically\\\\nimprove evaluations of factual correctness and\\\\nreduce </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hallucination going unnoticed. Tool-\\\\nusing judges could also simulate user inter-\\\\naction \\\\u2013 e.g\\n[Quote </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity] . Appendix G provides</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">more detail about our\\\\nrecruitment and incentivization process.\\\\nThe repositories themselves are large and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mature. On average, they have 23,000 stars, 1,100,000\\\\nlines of code, 4,900 forks, 20,000 commits, and 710 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">committers, and they broadly have very high\\\\nquality bars for code contributions. For example, one set of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">repository contribution guidelines con-\\\\ncludes: \\\\u201cPhew. While the above may be a lot to remember [..] the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">motivation for enforcing process\\\\nis to ensure that all code contributions meet a certain quality </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">threshold.\\\\u201d Section G.7 details further\\\\nstatistics about individual developers and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">repositories.\\\\n4\\\\nFigure 3: Real issues completed during the study from the stdlibjs and mito </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">repositories\\\\n2.2\\\\nExperimental Design\\\\nEach developer provides a list of real issues in their repository to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">work on as part of this study.\\\\nIssues are typically bug reports, feature requests, or work items used to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coordinate development\\n[Quote from AI Research Agents for Machine Learning: Search, Exploration, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Generalization in MLE-bench] . Superimage, a container image, provides a base set of tools required for common ML </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\\\nThis image includes pre-configured CUDA support, key deep learning frameworks such as PyTorch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\\\nTensorFlow, and essential data science libraries. Each coding session starts from the original </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Superimage\\\\nstate and can diverge based on the agent\\\\u2019s actions while not affecting the state of the other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents.\\\\nTogether, these design choices create a stable and robust testbed that eliminates confounders at both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\nsystem and implementation levels. This reliability enables reproducible benchmarking and facilitates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\\\ndevelopment of long-running agentic systems across thousands of parallel runs and diverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\\\n3.3\\\\nMLE-bench\\\\nMLE-bench (Chan et al., 2025) comprises of 75 tasks sourced from Kaggle, designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assess the capabilities\\\\nof agents in machine learning engineering\\n[Quote from Measuring the Impact of Early-2025</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AI on Experienced Open-Source Developer Productivity] . We additionally collect rich statistics from source-code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manage-\\\\nment systems, interview and survey participating developers, and conduct subset analyses to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">better\\\\nunderstand the nature of the slowdown result.\\\\nUsing these various sources of data, we identify 21 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">properties of our setting and experimental de-\\\\nsign that we hypothesize a priori may contribute to the slowdown </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effect. We group these factors\\\\ninto four categories: a) direct productivity loss, b) experimental artifact, c) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">factors raising human\\\\nperformance, and d) factors limiting AI performance. We find evidence that 5 factors </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contribute to\\\\nthe slowdown effect, we find mixed/unclear/no evidence for 10 factors, and we find evidence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against\\\\n6 factors contributing to the slowdown effect. Section 3.3 presents these factors at a high level, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\\\nAppendix C discusses each factor in detail\\n\\n\\n (Answer only from retrieval. Only cite sources that are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used. Make your response conversational.)'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">            </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        ),</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">content</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'tell me a cool fact'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">additional_kwargs</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={}, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response_metadata</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={})</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ]</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mmessages\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mSystemMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'You are a document chatbot. Help the user as they ask questions about documents. User messaged\u001b[0m\n",
       "\u001b[32mjust asked: tell me a cool fact\\n\\n From this, we have retrieved the following potentially-useful info:  \u001b[0m\n",
       "\u001b[32mConversation History Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Document\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Agent previously responded with RAG seems to refer to a \u001b[0m\n",
       "\u001b[32mconcept from the document \"AI Research Agents for Machine Learning: Search, Exploration, and Generalization in \u001b[0m\n",
       "\u001b[32mMLE-bench\" from the year 2025. However, the document does not provide a clear definition or explanation of RAG on \u001b[0m\n",
       "\u001b[32mits own. I had to make some assumptions based on the context provided.\\n\\nFrom what I can gather, RAG might be an \u001b[0m\n",
       "\u001b[32macronym for \"Reinforcement Agent in Graph,\" which is a hypothetical concept introduced in the document. This \u001b[0m\n",
       "\u001b[32mconcept is used to describe a type of AI research agent that operates within a search graph, where nodes represent \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mpartial\u001b[0m\u001b[32m)\u001b[0m\u001b[32m solutions to a given problem.\\n\\nIn this context, RAG maintains a search graph whose nodes are candidate \u001b[0m\n",
       "\u001b[32msolutions, and at each iteration, the agent selects nodes via a selection policy, picks an operator via an operator\u001b[0m\n",
       "\u001b[32mpolicy, and scores the resulting solution via a fitness function.\\n\\nThe document mentions RAG as a part of the \u001b[0m\n",
       "\u001b[32mAIRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAI Research Agent\u001b[0m\u001b[32m)\u001b[0m\u001b[32m framework, which is designed to solve real-world machine learning problems by searching \u001b[0m\n",
       "\u001b[32mand iteratively modifying existing solutions to generate new candidate solutions.\\n\\nSources:\\n\\n* AI Research \u001b[0m\n",
       "\u001b[32mAgents for Machine Learning: Search, Exploration, and Generalization in MLE-bench. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Retrieved from \u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote \u001b[0m\n",
       "\u001b[32mfrom AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from \u001b[0m\n",
       "\u001b[32mDocument\u001b[0m\u001b[32m]\u001b[0m\u001b[32m User previously responded with Tell me about RAG!\\n\\n\\n Document Retrieval:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from When AIs Judge \u001b[0m\n",
       "\u001b[32mAIs: The Rise of Agent-as-a-Judge Evaluation for LLMs\u001b[0m\u001b[32m]\u001b[0m\u001b[32m .\\\\n\\\\u2022 Integrating Tool Use in Judges: Agent \u001b[0m\n",
       "\u001b[32mjudges\\\\nthat can use tools \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlike search engines, code\\\\ninterpreters, calculators\u001b[0m\u001b[32m)\u001b[0m\u001b[32m will become more\\\\nimportant as\u001b[0m\n",
       "\u001b[32mtasks get complex or require live\\\\ndata verification. We might see hybrid evalua-\\\\ntor agents: for example, an \u001b[0m\n",
       "\u001b[32magent that, when\\\\nevaluating a factual answer, automatically\\\\nconsults a knowledge base or the web to \u001b[0m\n",
       "\u001b[32mfact-\\\\ncheck statements. This would dramatically\\\\nimprove evaluations of factual correctness and\\\\nreduce \u001b[0m\n",
       "\u001b[32mhallucination going unnoticed. Tool-\\\\nusing judges could also simulate user inter-\\\\naction \\\\u2013 e.g\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote \u001b[0m\n",
       "\u001b[32mfrom Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Appendix G provides\u001b[0m\n",
       "\u001b[32mmore detail about our\\\\nrecruitment and incentivization process.\\\\nThe repositories themselves are large and \u001b[0m\n",
       "\u001b[32mmature. On average, they have 23,000 stars, 1,100,000\\\\nlines of code, 4,900 forks, 20,000 commits, and 710 \u001b[0m\n",
       "\u001b[32mcommitters, and they broadly have very high\\\\nquality bars for code contributions. For example, one set of \u001b[0m\n",
       "\u001b[32mrepository contribution guidelines con-\\\\ncludes: \\\\u201cPhew. While the above may be a lot to remember \u001b[0m\u001b[32m[\u001b[0m\u001b[32m..\u001b[0m\u001b[32m]\u001b[0m\u001b[32m the \u001b[0m\n",
       "\u001b[32mmotivation for enforcing process\\\\nis to ensure that all code contributions meet a certain quality \u001b[0m\n",
       "\u001b[32mthreshold.\\\\u201d Section G.7 details further\\\\nstatistics about individual developers and \u001b[0m\n",
       "\u001b[32mrepositories.\\\\n4\\\\nFigure 3: Real issues completed during the study from the stdlibjs and mito \u001b[0m\n",
       "\u001b[32mrepositories\\\\n2.2\\\\nExperimental Design\\\\nEach developer provides a list of real issues in their repository to \u001b[0m\n",
       "\u001b[32mwork on as part of this study.\\\\nIssues are typically bug reports, feature requests, or work items used to \u001b[0m\n",
       "\u001b[32mcoordinate development\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from AI Research Agents for Machine Learning: Search, Exploration, and \u001b[0m\n",
       "\u001b[32mGeneralization in MLE-bench\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . Superimage, a container image, provides a base set of tools required for common ML \u001b[0m\n",
       "\u001b[32mtasks.\\\\nThis image includes pre-configured CUDA support, key deep learning frameworks such as PyTorch \u001b[0m\n",
       "\u001b[32mand\\\\nTensorFlow, and essential data science libraries. Each coding session starts from the original \u001b[0m\n",
       "\u001b[32mSuperimage\\\\nstate and can diverge based on the agent\\\\u2019s actions while not affecting the state of the other \u001b[0m\n",
       "\u001b[32magents.\\\\nTogether, these design choices create a stable and robust testbed that eliminates confounders at both \u001b[0m\n",
       "\u001b[32mthe\\\\nsystem and implementation levels. This reliability enables reproducible benchmarking and facilitates \u001b[0m\n",
       "\u001b[32mthe\\\\ndevelopment of long-running agentic systems across thousands of parallel runs and diverse \u001b[0m\n",
       "\u001b[32mtasks.\\\\n3.3\\\\nMLE-bench\\\\nMLE-bench \u001b[0m\u001b[32m(\u001b[0m\u001b[32mChan et al., 2025\u001b[0m\u001b[32m)\u001b[0m\u001b[32m comprises of 75 tasks sourced from Kaggle, designed to \u001b[0m\n",
       "\u001b[32massess the capabilities\\\\nof agents in machine learning engineering\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mQuote from Measuring the Impact of Early-2025\u001b[0m\n",
       "\u001b[32mAI on Experienced Open-Source Developer Productivity\u001b[0m\u001b[32m]\u001b[0m\u001b[32m . We additionally collect rich statistics from source-code \u001b[0m\n",
       "\u001b[32mmanage-\\\\nment systems, interview and survey participating developers, and conduct subset analyses to \u001b[0m\n",
       "\u001b[32mbetter\\\\nunderstand the nature of the slowdown result.\\\\nUsing these various sources of data, we identify 21 \u001b[0m\n",
       "\u001b[32mproperties of our setting and experimental de-\\\\nsign that we hypothesize a priori may contribute to the slowdown \u001b[0m\n",
       "\u001b[32meffect. We group these factors\\\\ninto four categories: a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m direct productivity loss, b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m experimental artifact, c\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mfactors raising human\\\\nperformance, and d\u001b[0m\u001b[32m)\u001b[0m\u001b[32m factors limiting AI performance. We find evidence that 5 factors \u001b[0m\n",
       "\u001b[32mcontribute to\\\\nthe slowdown effect, we find mixed/unclear/no evidence for 10 factors, and we find evidence \u001b[0m\n",
       "\u001b[32magainst\\\\n6 factors contributing to the slowdown effect. Section 3.3 presents these factors at a high level, \u001b[0m\n",
       "\u001b[32mand\\\\nAppendix C discusses each factor in detail\\n\\n\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAnswer only from retrieval. Only cite sources that are \u001b[0m\n",
       "\u001b[32mused. Make your response conversational.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m            \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;35mHumanMessage\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;33mcontent\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'tell me a cool fact'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33madditional_kwargs\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;33mresponse_metadata\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatbot = gr.Chatbot(value = [[None, initial_msg]])\n",
    "demo = gr.ChatInterface(chat_gen, chatbot=chatbot).queue()\n",
    "\n",
    "try:\n",
    "    demo.launch(debug=True, share=True, show_api=False)\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    demo.close()\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCb3RVVfbmQ0",
   "metadata": {
    "id": "yCb3RVVfbmQ0"
   },
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 4:** Saving Your Index For Evaluation\n",
    "\n",
    "After you've implemented your RAG chain, please save your accumulated vector store as shown [in the official documentation](https://python.langchain.com/docs/integrations/vectorstores/faiss#saving-and-loading). You'll have a chance to use it again for your final assessment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Y4se5wQ4Afda",
   "metadata": {
    "id": "Y4se5wQ4Afda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n"
     ]
    }
   ],
   "source": [
    "## Save and compress your index\n",
    "docstore.save_local(\"docstore_index\")\n",
    "!tar czvf docstore_index.tgz docstore_index\n",
    "\n",
    "!rm -rf docstore_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LsI7NivbIgFw",
   "metadata": {
    "id": "LsI7NivbIgFw"
   },
   "source": [
    "If everything was properly saved, the following line can be invoked to pull the index from the compressed `tgz` file (assuming the pip requirements are installed). After you have confirmed that the cell can pull in your index, download `docstore_index.tgz` for use in the last notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Qs8820ucIu1t",
   "metadata": {
    "id": "Qs8820ucIu1t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n",
      ". Results shown are for agents using R1. Bars depict the absolute\\nperformance gap between three configurations: (i) using the validation metric for both intermediate (search) and final\\n(submission) node selection; (ii) using the validation metric only for search and the test metric for selection; and (iii)\\nusing the test metric for both search and selection. b) Bridging the validation\\u2013test gap. Medal rate achieved by two\\nfinal node selection strategies as a function of k: (i) randomly sampling k nodes and reporting the highest test score\\namong them; (ii) selecting the top k nodes by validation score and reporting the highest test score among those. As k\\nincreases, the validation-based strategy closes the gap to the upper-bound performance given by the best test score\\nover the entire search graph.\\npattern. We observe that the rankings between agents change over time. For example, at the 3-hour mark,\\nthe performance gap between AIRAgreedy and AIRAmcts is notable\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "!tar xzvf docstore_index.tgz\n",
    "new_db = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(\"Testing the index\")\n",
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "as_3vWJGKB2F",
   "metadata": {
    "id": "as_3vWJGKB2F"
   },
   "source": [
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 5:** Wrap-Up\n",
    "\n",
    "Congratulations! Assuming your RAG chain is all good, you're now ready to move on to the **RAG Evaluation [Assessment]** section!\n",
    "\n",
    "### <font color=\"#76b900\">**Great Job!**</font>\n",
    "\n",
    "### **Next Steps:**\n",
    "1. **[Optional]** Revisit the **\"Questions To Think About\" Section** at the top of the notebook and think about some possible answers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4",
   "metadata": {
    "id": "8098de2f-32b3-428e-8f3b-f54141ec40b4"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
