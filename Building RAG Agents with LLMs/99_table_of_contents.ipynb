{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#76b900\">**Table Of Contents**</font>\n",
    "\n",
    "\n",
    "### **Welcome to the course!** \n",
    "\n",
    "Please navigate through the notebooks and feel free to explore other other components as something peaks your interest.\n",
    "\n",
    "#### **Microservices:**\n",
    "- **`./chatbot`**: A basic chatbot interface which allows several accesses to multiple models.\n",
    "    - **Basic:** No system message, just LLM access. ***Falls out of developments in Notebook 6.***\n",
    "    - **Context:** Loads in the context of the specified notebooks (context tab) at the start. ***Falls out of developments in Notebook 6.***\n",
    "    - **Agentic:** Tries to load in notebooks from environment and reason about it. ***Falls out of developments in Notebook 7.5.***\n",
    "- **`./composer`**: The spinup routine used to construct the environment. Can technically be used to replicate environment (advanced use-case).\n",
    "- **`./docker-router`**: A helper microservice (for advanced use/TA help). Also used to facilitate assessment.\n",
    "- **`./frontend`**: A course-specific chatbot window which will be used throughout the course, ***including for the final assessment.***\n",
    "- **`./llm_client`**: Enables API access to [`build.nvidia.com`](build.nvidia.com), which hosts NVIDIA NIM endpoints. Used in notebooks 6+.\n",
    "\n",
    "#### **Caches**\n",
    "- **`./imgs`**: Images from the course (used in the notebooks).\n",
    "- **`./slides`**: Important slides from the presentation.\n",
    "- **`./solutions`**: Solutions to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Using The Course Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var url = 'http://'+window.location.host+':8999';\n",
       "element.innerHTML = '<a style=\"color:#76b900;\" target=\"_blank\" href='+url+'><h2>< Link To Gradio Chatbot ></h2></a>';\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "var url = 'http://'+window.location.host+':8999';\n",
    "element.innerHTML = '<a style=\"color:#76b900;\" target=\"_blank\" href='+url+'><h2>< Link To Gradio Chatbot ></h2></a>';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Using The Course Exercise Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var url = 'http://'+window.location.host+':8090';\n",
       "element.innerHTML = '<a style=\"color:#76b900;\" target=\"_blank\" href='+url+'><h2>< Link To Gradio Frontend ></h2></a>';\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "var url = 'http://'+window.location.host+':8090';\n",
    "element.innerHTML = '<a style=\"color:#76b900;\" target=\"_blank\" href='+url+'><h2>< Link To Gradio Frontend ></h2></a>';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Using Docker-Router To Read Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frontend\n",
      "c-fx-15-v1-task1_nginx_1\n",
      "frontend_rproxy\n",
      "docker_router\n",
      "llm_client\n",
      "c-fx-15-v1-task1_assessment_1\n",
      "jupyter-notebook-server\n",
      "dli-logserv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "for entry in requests.get(\"http://docker_router:8070/containers\").json():\n",
    "    if entry.get(\"status\") == 'running':\n",
    "        print(entry.get(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-06 13:06:38 +0000] [7] [INFO] Starting gunicorn 22.0.0\n",
      "[2025-08-06 13:06:38 +0000] [7] [INFO] Listening at: http://0.0.0.0:8999 (7)\n",
      "[2025-08-06 13:06:38 +0000] [7] [INFO] Using worker: uvicorn.workers.UvicornWorker\n",
      "[2025-08-06 13:06:38 +0000] [8] [INFO] Booting worker with pid: 8\n",
      "[2025-08-06 13:06:38 +0000] [9] [INFO] Booting worker with pid: 9\n",
      "[2025-08-06 13:06:38 +0000] [10] [INFO] Booting worker with pid: 10\n",
      "[2025-08-06 13:06:53 +0000] [9] [ERROR] Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/arbiter.py\", line 609, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/uvicorn/workers.py\", line 75, in init_process\n",
      "    super().init_process()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/workers/base.py\", line 134, in init_process\n",
      "    self.load_wsgi()\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/workers/base.py\", line 146, in load_wsgi\n",
      "    self.wsgi = self.app.wsgi()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
      "    self.callable = self.load()\n",
      "                    ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/app/wsgiapp.py\", line 58, in load\n",
      "    return self.load_wsgiapp()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/app/wsgiapp.py\", line 48, in load_wsgiapp\n",
      "    return util.import_app(self.app_uri)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gunicorn/util.py\", line 371, in import_app\n",
      "    mod = importlib.import_module(module)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/web/frontend_server.py\", line 18, in <module>\n",
      "    from frontend_block import get_demo\n",
      "  File \"/web/frontend_block.py\", line 38, in <module>\n",
      "    from conv_tool_caller import ConversationalToolCaller\n",
      "  File \"/web/conv_tool_caller.py\", line 12, in <module>\n",
      "    from langserve import RemoteRunnable\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langserve/__init__.py\", line 8, in <module>\n",
      "    from langserve.client import RemoteRunnable\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langserve/client.py\", line 24, in <module>\n",
      "    from httpx._types import AuthTypes, CertTypes, CookieTypes, HeaderTypes, VerifyTypes\n",
      "ImportError: cannot import name 'VerifyTypes' from 'httpx._types' (/usr/local/lib/python3.11/site-packages/httpx/_types.py)\n",
      "[2025-08-06 13:06:53 +0000] [9] [INFO] Worker exiting (pid: 9)\n",
      "[2025-08-06 13:06:55 +0000] [7] [ERROR] Worker (pid:9) exited with code 3\n",
      "[2025-08-06 13:06:55 +0000] [7] [ERROR] Worker (pid:8) was sent SIGTERM!\n",
      "[2025-08-06 13:06:55 +0000] [7] [ERROR] Worker (pid:10) was sent SIGTERM!\n",
      "[2025-08-06 13:06:55 +0000] [7] [ERROR] Shutting down: Master\n",
      "[2025-08-06 13:06:55 +0000] [7] [ERROR] Reason: Worker failed to boot.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_name = \"chatbot\"  ## Which microservice to look at\n",
    "# from_idx = -4000           ## - to see truncated output\n",
    "from_idx = 0             ## - to see full output\n",
    "print(requests.get(f\"http://docker_router:8070/containers/{service_name}/logs\").json()[\"logs\"][from_idx:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
